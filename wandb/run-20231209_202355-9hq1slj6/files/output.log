Vocab size : 53
---------------------Starting training---------------------
  0%|                                                                                                                                                                                     | 0/11895 [00:00<?, ?it/s]
loss for step 0 : 0.021002068519592285


















































 99%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎ | 198/200 [01:41<00:01,  1.93it/s]

100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 200/200 [01:42<00:00,  1.91it/s]








































































































































  2%|██▊                                                                                                                                                                      | 200/11895 [08:44<4:24:24,  1.36s/it]
loss for step 200 : 2.519390035867691


















































100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏| 199/200 [01:42<00:00,  1.97it/s]

100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 200/200 [01:43<00:00,  1.95it/s]
 by io, wno as rmpproudig d id, tonismon veawal t t ticetig. ge, g. fts hrsth ngis h thofobederes inticutct ohos. r h s fobade, schos issm a arkirsa owischt jeend; arianindent icktivicait he ar eitserestad o fonnthar s v, canimea ferineraisluh t t] fe hnted for cat piandaitheaythesdstieres obe t ncatent ofe, sed sisthalc
tofores.







































































































































  3%|█████▋                                                                                                                                                                   | 400/11895 [15:13<4:17:23,  1.34s/it]
  0%|                                                                                                                                                                                       | 0/200 [00:00<?, ?it/s]



















































100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏| 199/200 [01:42<00:00,  1.94it/s]


  3%|█████▋                                                                                                                                                                 | 401/11895 [17:11<115:56:58, 36.32s/it]
 ofale boun skicrfaiabo thevrt wan thithagin borgemareasthow ust barril theteitistoudiecil ithetinthabrtirso ca dnd inese te, s stealed oromonlof ket, ints.
ef sume r anutonginthef trarartesoumevingabitint be cishithemessede ant pamad hma thomewat be anthoen oly beemint thrchabovithhrstrtheche jomomas. illigme fusthemuthis e.





































































































































  5%|████████▌                                                                                                                                                                | 600/11895 [21:37<4:12:17,  1.34s/it]
loss for step 600 : 6.544693085551262


















































100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏| 199/200 [01:42<00:00,  1.91it/s]


  5%|████████▍                                                                                                                                                              | 601/11895 [23:34<113:16:01, 36.10s/it]
 wre tubingennen oumar e anatt wan oziaroven ggewariuponcarl casknintaisthansiow chapolingey wrye, pohentaviscan wanton bugheat'sten ouge d lope itay. cadsthert f ogyce asthit, r is wiesoun orissthat ye coma, tot s; t, nuge, att ared, anteles ougare larontsthelafoncon oncauagas fiprelistaratte whare pon pe hongargivatole ar lsthom.
lle ilarresonge.

























  5%|█████████                                                                                                                                                                | 638/11895 [24:24<4:12:57,  1.35s/it]Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x164a25e50>
Traceback (most recent call last):
  File "/Users/hugo/Desktop/Projects/conditionned_theatre_play_generation/.env/lib/python3.8/site-packages/torch/utils/data/dataloader.py", line 1477, in __del__
    def __del__(self):
  File "/Users/hugo/Desktop/Projects/conditionned_theatre_play_generation/.env/lib/python3.8/site-packages/torch/utils/data/_utils/signal_handling.py", line 66, in handler
    _error_if_any_worker_fails()
RuntimeError: DataLoader worker (pid 68883) is killed by signal: Interrupt: 2.
  5%|█████████                                                                                                                                                                | 638/11895 [24:25<7:10:53,  2.30s/it]
Traceback (most recent call last):
  File "train.py", line 217, in <module>
    step(model, optimizer, scheduler, train_loader, test_dataset, device, epoch, path, best_loss = 1000)
  File "train.py", line 55, in step
    loss.backward()
  File "/Users/hugo/Desktop/Projects/conditionned_theatre_play_generation/.env/lib/python3.8/site-packages/torch/_tensor.py", line 492, in backward
    torch.autograd.backward(
  File "/Users/hugo/Desktop/Projects/conditionned_theatre_play_generation/.env/lib/python3.8/site-packages/torch/autograd/__init__.py", line 251, in backward
    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
KeyboardInterrupt